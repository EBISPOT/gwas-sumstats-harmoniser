/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    EBISPOT/gwas-sumstats-harmoniser Nextflow config file
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Default config options for all compute environments
----------------------------------------------------------------------------------------
*/

// Global default params, used in configs

params {

// global parameter
chromlist                = null
chrom                    = null
ref                      = null

//reference preparation
reference                = null
remote_vcf_location      = null
remote_ensembl_variation = null


// External user running
harm                     = null
to_build                 = null
threshold                = null
file                     = null
list                     = null

// GWAS catalog routine running
gwascatalog              = null
all_harm_folder          = null
inputPath                = null
ftp                      = null
failed                   = null

}

// Load nf-core custom profiles from different Institutions
try {
    includeConfig "${params.custom_config_base}/nfcore_custom.config"
} catch (Exception e) {
    System.err.println("WARNING: Could not load nf-core/config profiles: ${params.custom_config_base}/nfcore_custom.config")
}

manifest {
    name            = 'EBISPOT/gwas-sumstats-harmoniser'
    defaultBranch   = 'nextflow'
    homePage        = 'https://github.com/EBISPOT/gwas-sumstats-harmoniser/'
    mainScript      = 'main.nf'
}


if (params.reference) {
if (!params.harm & !params.gwascatalog) {
    includeConfig 'config/reference.config'
    if (params.chromlist){
    params.chrom = params.chromlist?.tokenize(',') as List
    }
  }
}

if (params.harm) {
if (!params.reference & !params.gwascatalog) {
    includeConfig 'config/lsf.config'
}
}

if (params.gwascatalog) {
if (!params.harm & !params.reference) {
    includeConfig 'config/gwascatalog.config'
}
}

profiles {
    debug { process.beforeScript = 'echo $HOSTNAME' }
    
    standard {
        process.executor = 'local'
    }
    
    cluster {
        process.executor = 'lsf'
        process.queue = 'short'
    }
    
    docker {
        docker.enabled         = true
        docker.userEmulation   = true
        docker.runOptions      = '-u $(id -u):$(id -g)'
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    
    singularity {
        singularity.enabled    = true
        singularity.autoMounts = true
        docker.enabled         = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}
